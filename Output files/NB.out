Validation Results:
Classification Report:
               precision    recall  f1-score   support

           0       0.98      0.86      0.92      3849
           1       0.87      0.99      0.92      3625
       label       0.00      0.00      0.00         1

    accuracy                           0.92      7475
   macro avg       0.62      0.62      0.61      7475
weighted avg       0.93      0.92      0.92      7475

Test Results:
Classification Report:
               precision    recall  f1-score   support

           0       0.80      0.82      0.81      3790
           1       0.81      0.78      0.80      3683
       label       0.00      0.00      0.00         1

    accuracy                           0.80      7474
   macro avg       0.54      0.54      0.54      7474
weighted avg       0.80      0.80      0.80      7474

Confusion matrix has been saved to 'confusion_matrix.csv'.
